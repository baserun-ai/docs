---
title: "Logging LLM requests"
sidebarTitle: "Logging LLM requests"
description: "Start logging your LLM requests with 2 lines of code changes."
---

## Introduction

When the Baserun SDK is initialized explicitly or via our testing plugins, all OpenAI and Anthropic requests are automatically logged with no additional code changes.

For an in-depth overview of how our logging data is structured, please see our Logging Overview page.

![Logging LLM requests](/images/trace_llm_request.png)

## Use case

Get insight into individual LLM requests, including prompt templates, input, output, duration, token usage cost, and duration.

## Features

- Support Python and Typescript
- Automatically logging
- Provide generative token usage and context token usage
- Provide estimated cost
- Support evaluation
- Provide duration
- Supports async functions
- Support user feedback

## Instructions

<Steps>
<Step title="Install Baserun SDK">

<CodeGroup>

    ```bash python
    pip install baserun
    ```

    ```bash typescript
    npm install baserun
    # or
    yarn add baserun
    ```

</CodeGroup>
</Step>
<Step title="Generate an API key">

Create an account at [https://baserun.ai](https://baserun.ai). Then generate an API key for your project in the [settings](https://baserun.ai/settings) tab. Set it as an environment variable:

```bash
export BASERUN_API_KEY="your_api_key_here"
```

Or if using python, set `baserun.api_key` to its value:

```python
baserun.api_key = "br-..."
```

</Step>
<Step title="Initialize Baserun">

At your application's startup, define the environment in which you'd like to run Baserun. You can use Baserun in the development environment while iterating on your features, utilizing it for debugging and analysis, or in the production environment to monitor your application.

<CodeGroup>
```python python
import baserun
import openai
openai.api_key = YOUR_OPEANI_API_KEY_HERE

def example():
response = openai.chat.completions.create(
model="gpt-3.5-turbo",
temperature=0.7,
messages=[
{
"role": "user",
"content": "What are three activities to do in Paris?"
}
],
)
return response.choices[0].message

if **name** == "**main**":
baserun.init()
print(example())

````

```typescript typescript
import {baserun} from 'baserun';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: YOUR_OPEANI_API_KEY_HERE,
});


async function example() {
  const chatCompletion = await openai.chat.completions.create({
    messages: [{ role: 'user', content: 'What are three activities to do in Paris?' }],
    model: 'gpt-3.5-turbo',
  });
  return chatCompletion.choices[0].message.content;
}


baserun.init();
example().then(output => {
    console.log("Output:", output);
  }).catch(error => {
    console.error("Error:", error);
  });
````

</CodeGroup>
</Step>
</Steps>

## Example

<CodeGroup>

```python python
import baserun
import openai

def example():
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        temperature=0.7,
        messages=[
            {
                "role": "user",
                "content": "What are three activities to do in Paris?"
            }
        ],
    )
    return response.choices[0].message


if __name__ == "__main__":
    openai.api_key = YOUR_OPEANI_API_KEY_HERE
    baserun.init()
    print(example())

```

```typescript typescript
import { baserun } from "baserun";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: YOUR_OPEANI_API_KEY_HERE,
});

async function example() {
  const chatCompletion = await openai.chat.completions.create({
    messages: [
      { role: "user", content: "What are three activities to do in Paris?" },
    ],
    model: "gpt-3.5-turbo",
  });
  return chatCompletion.choices[0].message.content;
}

baserun.init();
example()
  .then((output) => {
    console.log("Output:", output);
  })
  .catch((error) => {
    console.error("Error:", error);
  });
```

</CodeGroup>

Congrats, you are done! Now, you can navigate to the monitoring tab. You should see your request logged in the monitoring tab.

## Demo projects

[Python example repo](https://github.com/baserun-ai/testing-agent/), <br />
[Typescript example repo](https://github.com/baserun-ai/testing-agent-js)

If you have any questions or feature requests, join our [Discord channel](https://discord.com/invite/xEPFsvSmkb) or send us an email at [hello@baserun.ai](mailto:hello@baserun.ai)
