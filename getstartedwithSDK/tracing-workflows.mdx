---
title: "Tracing multi-Step LLM workflows"
sidebarTitle: Tracing multi-Step LLM workflows
---

### Introduction

A Trace comprises a series of events executed within an LLM chain(workflow). Tracing enables Baserun to capture and display the LLM chain's entire lifecycle, whether synchronous or asynchronous.

Tracing LLM chains allows you to debug your application, monitor your LLM chains' performance, and also collect user feedback.

<Frame>![Trace a LLM chain](/images/monitor-trace-details.png)</Frame>

### Use cases

Please reference the [Monitoring Overview](/monitoring/overview) to learn why logging LLM chain is critical for LLM feature development.

### Features

- Automatically logs OpenAI and Anthropic LLM calls
- UI to show sequence of events
- Provide generative token usage, context token usage, estimated cost, duration
- Support automatic evaluation
- Supports async functions
- Option to add custom trace name
- Option to log custom metadata
- Option to set trace result
- Support collecting user feedback

<Note>
  If you are using Next.js, please reference [Logging > Tracing with
  Next.js](/logging/tracingwithnextjs) .
</Note>

### Instruction

The first 3 steps are the same as the [Logging LLM requests tutorial](/). So, if you have already done this before, jump to step 4.

<Steps>
<Step title="Install Baserun SDK">

<CodeGroup>

    ```bash python
    pip install baserun
    ```

    ```bash typescript
    npm install baserun
    # or
    yarn add baserun
    ```

</CodeGroup>
</Step>
<Step title="Generate an API key">

Create an account at [https://baserun.ai](https://baserun.ai). Then generate an API key for your project in the [settings](https://baserun.ai/settings) tab. Set it as an environment variable:

```bash
export BASERUN_API_KEY="your_api_key_here"
```

Alternatively set the Baserun API key when initializing the SDK

<CodeGroup>

```python python

import baserun

baserun.api_key = "br-..."

baserun.init()
```

```typescript typescript
import { baserun } from "baserun";

// init needs to be awaited. If top-level await is not available, wrap it in an async function,
// but make sure it is called before instantiating OpenAI, Anthropic or Replicate
await baserun.init({
  apiKey: "br-...",
});
```

</CodeGroup>

</Step>
<Step title=" Initialize Baserun">

At your application's startup, define the environment in which you'd like to run Baserun. You can use Baserun in the development environment while iterating on your features, utilizing it for debugging and analysis, or in the production environment to monitor your application.

<CodeGroup>

```python python
import baserun

baserun.init()

```

```typescript typescript
import { baserun } from "baserun";

// in your main function

// init needs to be awaited. If top-level await is not available, wrap it in an async function,
// but make sure it is called before instantiating OpenAI, Anthropic or Replicate
await baserun.init();
```

</CodeGroup>
</Step>
<Step title="Decide what to trace">

The function(s) to trace are ultimately dependent on your app. It could be a main() function, or it could be a handler for an API call.

Note for TS/JS: Make sure to always call `await baserun.init()` before you instantiate OpenAI, Anthropic or Replicate.

<CodeGroup>
```python python
import baserun

@baserun.trace
def run_chatbot():
    client = OpenAI()
    user_input = None

    while user_input != "exit":
        user_input = get_user_input()
        conversation.append({"role": "user", "content": user_input})

        completion = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=conversation,
        )
````

```typescript typescript
import { baserun } from 'baserun'

const getResponse = baserun.trace((message: string) => {
  ...
}, 'getResponse')

````

</CodeGroup>
</Step>
</Steps>

### Full Example

<CodeGroup>

```python python
from uuid import uuid4
from openai import OpenAI

import baserun

PROMPT = """As a customer service representative for an online pet product retailer, your main goal is to
provide a positive and informative chat experience for customers..."""


def run_chatbot():
    client = OpenAI()
    conversation = [{"role": "system", "content": PROMPT}]
    conversation_id = str(uuid4())

    print(f"Start your conversation. Type `exit` to end the conversation.\n> ", end="")
    user_input = input()
    conversation.append({"role": "user", "content": user_input})

    # Start a trace before your first OpenAI call, giving it a name
    with baserun.start_trace(name="Chatbot CLI loop") as trace:
        # Tracing allows each iteration's LLM calls to be grouped together
        while user_input != "exit":
            completion = client.chat.completions.create(
                model="gpt-4-1106-preview",
                messages=conversation,
            )
            content = completion.choices[0].message.content
            conversation.append({"role": "assistant", "content": content})

            print(f"{content}\n> ", end="")
            user_input = input()
            conversation.append({"role": "user", "content": user_input})

        # Set the trace result for display in the Baserun UI (here it is set to the last user input)
        trace.result = user_input

        print("How would you rate this conversation on a scale of 1 to 10?\n> ", end="")
        user_feedback = input()

        # Annotate the trace with additional information, such as user feedback
        annotation = baserun.annotate(trace=trace)
        annotation.log("Conversation ID", {"conversation_id": conversation_id})
        annotation.feedback("Chatbot conversation rating", score=int(user_feedback))
        annotation.submit()


if __name__ == "__main__":
    baserun.api_key = YOUR_BASERUN_API_KEY_HERE
    openai.api_key = YOUR_OPEANI_API_KEY_HERE
    baserun.init()
    run_chatbot()
```

```typescript typescript
import OpenAI from "openai";
import { baserun } from "baserun";

const openai = new OpenAI();

async function main() {
  await baserun.init();

  await baserun.trace(
    async () => {
      baserun.log("lets go", "We are invoking OpenAI now");
      const res = await openai.completions.create({
        model: "gpt-3.5-turbo-instruct",
        prompt: "2+2=",
        temperature: 0.7,
      });

      baserun.log("TestEvent", "whatever");

      baserun.evals.includes("model name", res.model, "gpt-3.5-turbo-instruct");
    },
    {
      name: "the name of the trace", // this will show up in the Baserun UI
    }
  );
}

main();
```

</CodeGroup>

Congrats, you are done! Now, you can navigate to the monitoring tab. Here is what you will see interact with your application:

<Frame>![Trace list](/images/monitor_trace_list.png)</Frame>

Optionally, you can add metadata like trace name, user ID, and session ID to aid in debugging. Read [Logging > Advanced tracing features](/monitoring/advancedtracing) for more details.

## Demo projects

[Python example repo](https://github.com/baserun-ai/testing-agent/), <br />
[Typescript example repo](https://github.com/baserun-ai/testing-agent-js)

If you have any questions or feature requests, join our [Discord channel](https://discord.com/invite/xEPFsvSmkb) or send us an email at [hello@baserun.ai](mailto:hello@baserun.ai)
