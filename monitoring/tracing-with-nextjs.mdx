---
title: Tracing with Next.js
sidebarTitle: Tracing with Next.js
description: Start tracing your Next.js app.
---

<Steps>
<Step title="Install Baserun SDK">

<CodeGroup>

    ```bash typescript
    npm install baserun
    # or
    yarn add baserun
    ```

</CodeGroup>
</Step>
<Step title="Generate an API key">

Create an account at [https://app.baserun.ai/sign-up](https://app.baserun.ai/sign-up). Then generate an API key for your project in the [settings](https://abaserun.ai/settings) tab and set it as an environment variable.

```bash
export BASERUN_API_KEY="your_api_key_here"
```

</Step>
<Step title="Initialize baserun">

You need to initialize Baserun in a body of every request handler where you want to use it.

```typescript your-project/instrumentation.ts
export const POST = async (req: any) => {
  await baserun.init()
  // your request handler code
}
```
</Step>
</Steps>

## Example

In this example, we're using Vercel's [ai](https://www.npmjs.com/package/ai) npm package to stream the result of an OpenAI chat completion to the client.
Note, that Baserun doesn't support `export const runtime = "edge";`, we we're keeping this in an ordinary Lambda function deployed by Vercel.

```typescript ./app/api/chat/route.ts
import OpenAI from 'openai'
import { OpenAIStream, StreamingTextResponse } from 'ai'
import { baserun } from 'baserun'

const openai = new OpenAI()

export const POST = async (req: any) => {
  await baserun.init()

  const stream = baserun.trace(async () => {
    const { messages } = await req.json()
    const response = await openai.chat.completions.create({
      model: "gpt-4",
      stream: true,
      messages,
    })
    return OpenAIStream(response)
  }, "chat route")

  return new StreamingTextResponse(await stream())
}

```

## Full example

You can check out a full example on how to use Baserun with Next.js [here](https://github.com/baserun-ai/baserun-next).
