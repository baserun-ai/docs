{/* TODO: this page is basically the same thing as monitoring/collect-user-feedback. not sure what to do with it */}

## Capturing Annotations

Annotations are a term we use to refer to events and metadata that can be attached to a trace or an individual LLM request. Examples are logs, user feedback, evals, and checks.

To associate these annotations with a trace, you need to create an Annotation.

In order to create an Annotation, you use the `baserun.annotate` function:

<CodeGroup>
```python
@baserun.trace
def ask_question(question="What is the capital of the US?") -> str:
    completion = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[{"role": "user", "content": question}],
    )

    # Create the annotation
    annotation = baserun.annotate()

    # Capture whatever annotations you need
    annotation.feedback(
        name="annotate_feedback", score=0.8, metadata={"comment": "This is correct but not concise enough"}
    )
    annotation.check_includes("openai_chat.content", "Washington", content)
    annotation.log("OpenAI Chat Results", metadata={"result": content, "input": question})

    # Make sure to submit the annotation
    annotation.submit()

````
</CodeGroup>

To associate these annotations a particular LLM request, you simply need to pass the completion ID from your LLM request. To do so using OpenAI's SDK, you can do the following:

<CodeGroup>
```python
@baserun.trace
def ask_question(question="What is the capital of the US?") -> str:
    completion = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[{"role": "user", "content": question}],
    )

    # Create the annotation
    annotation = baserun.annotate(completion.id)

    # Capture whatever annotations you need
    annotation.feedback(
        name="annotate_feedback", score=0.8, metadata={"comment": "This is correct but not concise enough"}
    )
    annotation.check_includes("openai_chat.content", "Washington", content)
    annotation.log("OpenAI Chat Results", metadata={"result": content, "input": question})

    # Make sure to submit the annotation
    annotation.submit()
````

</CodeGroup>
